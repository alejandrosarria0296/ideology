{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f87bd4d-941b-421f-a997-ac940faf3bd4",
   "metadata": {},
   "source": [
    "## Libraries and UDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d25872-f8a6-488b-9c26-621950e2de27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General spark\n",
    "from pyspark import SparkContext, SparkContext\n",
    "\n",
    "#Working with dataframes\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession, Row, DataFrame\n",
    "from pyspark.sql.types import StructType, StructField, StringType, ArrayType, FloatType, IntegerType\n",
    "\n",
    "#Dimension reduction and clustering\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import StandardScaler, PCA\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "from pyspark.mllib.feature import StandardScaler as StandardScalerRDD\n",
    "from pyspark.mllib.linalg.distributed import RowMatrix\n",
    "\n",
    "#Regular python libraries\n",
    "import pandas as pd\n",
    "import ast\n",
    "import warnings\n",
    "import ast\n",
    "import pickle\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"dimension reduction and clustering\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e9cfcb-4d11-478e-a889-263dcb382335",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_vector(s):\n",
    "    try:\n",
    "        embedding = [float(x) for x in ast.literal_eval(s)]\n",
    "        return Vectors.dense(embedding)\n",
    "    except:\n",
    "        return None\n",
    "string_to_vector_udf = udf(string_to_vector, ArrayType(FloatType()))\n",
    "\n",
    "def cluster_and_evaluate_features(data, clust_model, evaluator):\n",
    "    model = clust_model.fir(data)\n",
    "    df_with_clusters = model.transform(df)\n",
    "    score = evaluator.evaluate(df_with_clusters)\n",
    "\n",
    "    if hasattr(clust_model, 'getK'):\n",
    "        num_clusters = clust_model.getK()\n",
    "    elif hasattr(clust_model, 'getNumClusters'):\n",
    "        num_clusters = clust_model.getNumClusters()\n",
    "    else:\n",
    "        num_clusters = 'Unknown\n",
    "\n",
    "    algorithm_name = type(clust_model).__name__\n",
    "    \n",
    "    print(f\"Score for {algorithm_name} with {num_clusters} clusters: {score}\")\n",
    "    return df_with_clusters, model\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c1b7d8-925c-4027-9a2f-935d0d870267",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d35ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"../data/interventions_sample.pkl\"\n",
    "\n",
    "interventions_pd_df = pd.read_pickle(path)\n",
    "interventions_df = spark.createDataFrame(interventions_pd_df)\n",
    "interventions_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d7801a-9c0a-4065-a855-aad68060d1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = interventions_df.select('session_id', 'intervention_id', 'embeddings_str')\n",
    "df = df.withColumn('features', string_to_vector_udf('embeddings_str'))\n",
    "df.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80d5035-fd83-4975-806b-f13c15dea4af",
   "metadata": {},
   "source": [
    "## Round 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bff00d-e5b0-4e6c-80b3-d6360d826c63",
   "metadata": {},
   "source": [
    "### Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214e3a18-badf-4513-ab5f-dfed2ebe2b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 5\n",
    "gmm = GaussianMixture(k=n_clusters, featuresCol='features', predictionCol='cluster', seed=0)\n",
    "kmeans = KMeans(k=n_clusters, featuresCol='features', predictionCol='cluster', seed=0)\n",
    "evaluator = ClusteringEvaluator(featuresCol='features', predictionCol='cluster', metricName='silhouette', distanceMeasure='squaredEuclidean')\n",
    "\n",
    "for alg in [gmm, kmeans]:\n",
    "    cluster_and_evaluate_features(df, alg, evaluator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bfd78c-2c80-4309-9912-e0dbb9adbf77",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ff39f2-dc95-4b1f-8630-8388a27ee0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = df.select('features').first()[0].size\n",
    "\n",
    "pca = PCA(k=embedding_dim, inputCol='features', outputCol='pca_features')\n",
    "pca_model = pca.fit(df)\n",
    "\n",
    "explained_variance = pca_model.explainedVariance.toArray()\n",
    "cumulative_variance = np.cumsum(explained_variance)\n",
    "num_components_90 = np.where(cumulative_variance >= 0.9)[0][0] + 1\n",
    "\n",
    "pca = PCA(k=num_components_90, inputCol='features', outputCol='pca_features')\n",
    "pca_model = pca.fit(df)\n",
    "df_pca = pca_model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ffe873-1638-4581-9026-9b40f905c6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = list(range(2, 51))\n",
    "\n",
    "for n in clusters:\n",
    "    gmm = GaussianMixture(k=n, featuresCol='features', predictionCol='cluster', seed=0)\n",
    "    kmeans = KMeans(k=n, featuresCol='features', predictionCol='cluster', seed=0)\n",
    "    for alg in [gmm, kmeans]:\n",
    "        cluster_and_evaluate_features(df_pca, alg, evaluator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975639ad-c7cd-40fc-8845-3953f65f327b",
   "metadata": {},
   "source": [
    "### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a69dee-0a1b-4ed0-a86d-ef4f1f020377",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_vectors = df.select('features').rdd.map(lambda row: Vectors.dense(row['features']))\n",
    "mat = RowMatrix(rdd_vectors)\n",
    "svd = mat.computeSVD(k=num_components_90, computeU=True)\n",
    "\n",
    "U_df = svd.U.rows.map(lambda row: Row(features=Vectors.dense(row.toArray()))).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb758ab9-a637-453f-91aa-591411724d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in clusters:\n",
    "    gmm = GaussianMixture(k=n, featuresCol='features', predictionCol='cluster', seed=0)\n",
    "    kmeans = KMeans(k=n, featuresCol='features', predictionCol='cluster', seed=0)\n",
    "    for alg in [gmm, kmeans]:\n",
    "        cluster_and_evaluate_features(U_df, alg, evaluator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22b180c-537f-49b1-99c7-f9ecf39f7821",
   "metadata": {},
   "source": [
    "### Best model\n",
    "SVD features, kmeans clustering, 4 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f042ce09-8a47-4aac-8b0e-7a45ba3f8434",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(k=4, featuresCol='features', predictionCol='cluster', seed=0)\n",
    "\n",
    "df_labels, _ = cluster_and_evaluate_features(U_df, kmeans, evaluator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c25a127-ce4c-49c2-9ea3-97e75db1ff4a",
   "metadata": {},
   "source": [
    "### Evaluate clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ad2e38-49eb-4e79-a2f2-cd4a38d185af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_random = df_labels.withColumn('random', F.rand())\n",
    "window_spec = Window.partitionBy('cluster').orderBy('random')\n",
    "df_sampled = df_with_random.withColumn('rank', F.row_number().over(window_spec)).filter(F.col('rank') <= 5)\n",
    "sampled_data = df_sampled.select('cluster', 'intervention_id').collect()\n",
    "\n",
    "cluster_dict = {}\n",
    "for row in sampled_data:\n",
    "    cluster = row['cluster']\n",
    "    intervention_id = row['intervention_id']\n",
    "    if cluster not in cluster_dict:\n",
    "        cluster_dict[cluster] = []\n",
    "    cluster_dict[cluster].append(intervention_id)\n",
    "\n",
    "for cluster, intervention_ids in cluster_dict.items():\n",
    "    print(f\"Cluster {cluster}\")\n",
    "    for intervention_id in intervention_ids:\n",
    "        text_row = interventions_df.filter(interventions_df['intervention_id'] == intervention_id).select('intervention_text').collect()\n",
    "        if text_row:\n",
    "            intervention_text = text_row[0]['intervention_text']\n",
    "            print(intervention_text[:100])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87662f9e-19ba-4f73-8471-cbac77226822",
   "metadata": {},
   "source": [
    "Cluster 2 contains interventions that were not properly filtered. Goin to filter and re cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e19cb05-0b25-4fd2-a168-1660b9d73883",
   "metadata": {},
   "source": [
    "## Round 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cb3c5a-4f17-40b3-9b86-96a955303188",
   "metadata": {},
   "source": [
    "### Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dd05fb-c8b0-421b-b624-ece79f43c647",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df.filter(df.cluster != 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffa4a9d-1622-40ec-bdc2-8e0569b5f39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 5\n",
    "gmm = GaussianMixture(k=n_clusters, featuresCol='features', predictionCol='cluster', seed=0)\n",
    "kmeans = KMeans(k=n_clusters, featuresCol='features', predictionCol='cluster', seed=0)\n",
    "evaluator = ClusteringEvaluator(featuresCol='features', predictionCol='cluster', metricName='silhouette', distanceMeasure='squaredEuclidean')\n",
    "\n",
    "for alg in [gmm, kmeans]:\n",
    "    cluster_and_evaluate_features(df, alg, evaluator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a63d9ee-ba8b-4cea-9911-92b22ab5d33d",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c833a53-acdc-4b1a-b6d1-0bf55f054cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = df_filtered.select('features').first()[0].size\n",
    "\n",
    "pca = PCA(k=embedding_dim, inputCol='features', outputCol='pca_features')\n",
    "pca_model = pca.fit(df_filtered)\n",
    "\n",
    "explained_variance = pca_model.explainedVariance.toArray()\n",
    "cumulative_variance = np.cumsum(explained_variance)\n",
    "num_components_90 = np.where(cumulative_variance >= 0.9)[0][0] + 1\n",
    "\n",
    "pca = PCA(k=num_components_90, inputCol='features', outputCol='pca_features')\n",
    "pca_model = pca.fit(df_filtered)\n",
    "df_pca = pca_model.transform(df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e957004e-f06d-46f6-889e-7b62c2816f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in clusters:\n",
    "    gmm = GaussianMixture(k=n, featuresCol='features', predictionCol='cluster', seed=0)\n",
    "    kmeans = KMeans(k=n, featuresCol='features', predictionCol='cluster', seed=0)\n",
    "    for alg in [gmm, kmeans]:\n",
    "        cluster_and_evaluate_features(df_pca, alg, evaluator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63201c78-c0cf-4cba-841e-57dc6451fbad",
   "metadata": {},
   "source": [
    "### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b0a079-a793-4561-b26a-6d3274815196",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_vectors = df_filtered.select('features').rdd.map(lambda row: Vectors.dense(row['features']))\n",
    "mat = RowMatrix(rdd_vectors)\n",
    "svd = mat.computeSVD(k=num_components_90, computeU=True)\n",
    "\n",
    "U_df = svd.U.rows.map(lambda row: Row(features=Vectors.dense(row.toArray()))).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acc672d-5322-42a5-b37a-4f0a7d71e77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in clusters:\n",
    "    gmm = GaussianMixture(k=n, featuresCol='features', predictionCol='cluster', seed=0)\n",
    "    kmeans = KMeans(k=n, featuresCol='features', predictionCol='cluster', seed=0)\n",
    "    for alg in [gmm, kmeans]:\n",
    "        cluster_and_evaluate_features(U_df, alg, evaluator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76f5fcd-3362-461d-9af2-ba7bdb72f66c",
   "metadata": {},
   "source": [
    "### Best model\n",
    "\n",
    "SVD features, kmeans clustering, 5 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c651574e-0e57-40bc-88d9-d316f1be3e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(k=5, featuresCol='features', predictionCol='cluster', seed=0)\n",
    "\n",
    "df_labels, _ = cluster_and_evaluate_features(U_df, kmeans, evaluator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5c4cf8-9357-423d-aeee-2b54344eb6c6",
   "metadata": {},
   "source": [
    "### Evaluate clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e600a3-e94d-4c05-aaf2-f85a92bc4a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_random = df_labels.withColumn('random', F.rand())\n",
    "window_spec = Window.partitionBy('cluster').orderBy('random')\n",
    "df_sampled = df_with_random.withColumn('rank', F.row_number().over(window_spec)).filter(F.col('rank') <= 5)\n",
    "sampled_data = df_sampled.select('cluster', 'intervention_id').collect()\n",
    "\n",
    "cluster_dict = {}\n",
    "for row in sampled_data:\n",
    "    cluster = row['cluster']\n",
    "    intervention_id = row['intervention_id']\n",
    "    if cluster not in cluster_dict:\n",
    "        cluster_dict[cluster] = []\n",
    "    cluster_dict[cluster].append(intervention_id)\n",
    "\n",
    "for cluster, intervention_ids in cluster_dict.items():\n",
    "    print(f\"Cluster {cluster}\")\n",
    "    for intervention_id in intervention_ids:\n",
    "        text_row = interventions_df.filter(interventions_df['intervention_id'] == intervention_id).select('intervention_text').collect()\n",
    "        if text_row:\n",
    "            intervention_text = text_row[0]['intervention_text']\n",
    "            print(intervention_text[:100])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d86dcf-8751-4026-b2f6-d8267def66cd",
   "metadata": {},
   "source": [
    "These seem more interpretable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306d5bbd-0d4a-4bb4-bb03-5dc4fa7f8c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels_pandas = df_labels.toPandas()\n",
    "\n",
    "output_path = \"../data/dataset_with_clusters.pkl\"\n",
    "with open(output_path, \"wb\") as file:\n",
    "    pickle.dump(df_labels_pandas, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
